{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- RGB Model -->\n",
    "<div class=\"alert\" style=\"background: linear-gradient(to right,rgb(255, 0, 0), rgb(0,255,0),rgb(0, 0, 255)); \n",
    "color:rgb(255, 255, 255);\">\n",
    "\n",
    "# **U-NET RGB Colorization Model - V2**\n",
    "***\n",
    "### **U-NET RGB Colorization Model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../Src')\n",
    "from unet_model import build_unet, get_callbacks\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "X_train = np.load(\"../Data/prepared_data/comic_input_grayscale_train.npy\")\n",
    "y_train = np.load(\"../Data/prepared_data/comic_output_color_train.npy\")\n",
    "X_test = np.load(\"../Data/prepared_data/comic_input_grayscale_test.npy\")\n",
    "y_test = np.load(\"../Data/prepared_data/comic_output_color_test.npy\")\n",
    "\n",
    "# Normalize input images to [-1, 1] range for better training with tanh\n",
    "X_train = (X_train - 0.5) * 2\n",
    "X_test = (X_test - 0.5) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile model\n",
    "input_shape = X_train.shape[1:]\n",
    "model = build_unet(input_shape)\n",
    "\n",
    "# Using a combination of MSE and MAE losses\n",
    "def combined_loss(y_true, y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()(y_true, y_pred)\n",
    "    return 0.84 * mse + 0.16 * mae\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=combined_loss,\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 22s/step - loss: 0.0645 - mae: 0.1540 - val_loss: 0.1230 - val_mae: 0.2684\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0467 - mae: 0.1256 - val_loss: 0.1218 - val_mae: 0.2667\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 22s/step - loss: 0.0390 - mae: 0.1114 - val_loss: 0.1213 - val_mae: 0.2660\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0344 - mae: 0.1028 - val_loss: 0.1203 - val_mae: 0.2645\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 23s/step - loss: 0.0333 - mae: 0.1015 - val_loss: 0.1189 - val_mae: 0.2625\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 24s/step - loss: 0.0291 - mae: 0.0915 - val_loss: 0.1172 - val_mae: 0.2600\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 22s/step - loss: 0.0279 - mae: 0.0891 - val_loss: 0.1157 - val_mae: 0.2578\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 23s/step - loss: 0.0272 - mae: 0.0876 - val_loss: 0.1140 - val_mae: 0.2553\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 24s/step - loss: 0.0269 - mae: 0.0868 - val_loss: 0.1121 - val_mae: 0.2527\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 23s/step - loss: 0.0253 - mae: 0.0835 - val_loss: 0.1106 - val_mae: 0.2504\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 23s/step - loss: 0.0247 - mae: 0.0812 - val_loss: 0.1089 - val_mae: 0.2480\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 23s/step - loss: 0.0239 - mae: 0.0794 - val_loss: 0.1071 - val_mae: 0.2454\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 23s/step - loss: 0.0242 - mae: 0.0797 - val_loss: 0.1055 - val_mae: 0.2431\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 23s/step - loss: 0.0240 - mae: 0.0796 - val_loss: 0.1039 - val_mae: 0.2407\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 23s/step - loss: 0.0233 - mae: 0.0776 - val_loss: 0.1030 - val_mae: 0.2392\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 23s/step - loss: 0.0241 - mae: 0.0790 - val_loss: 0.1011 - val_mae: 0.2364\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 23s/step - loss: 0.0227 - mae: 0.0760 - val_loss: 0.0986 - val_mae: 0.2327\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 23s/step - loss: 0.0219 - mae: 0.0742 - val_loss: 0.0965 - val_mae: 0.2298\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 23s/step - loss: 0.0231 - mae: 0.0771 - val_loss: 0.0949 - val_mae: 0.2275\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0223 - mae: 0.0749 - val_loss: 0.0932 - val_mae: 0.2249\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 21s/step - loss: 0.0224 - mae: 0.0749 - val_loss: 0.0909 - val_mae: 0.2214\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 21s/step - loss: 0.0216 - mae: 0.0734 - val_loss: 0.0890 - val_mae: 0.2186\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 21s/step - loss: 0.0219 - mae: 0.0736 - val_loss: 0.0873 - val_mae: 0.2158\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 22s/step - loss: 0.0212 - mae: 0.0718 - val_loss: 0.0855 - val_mae: 0.2130\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0208 - mae: 0.0708 - val_loss: 0.0832 - val_mae: 0.2095\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 21s/step - loss: 0.0215 - mae: 0.0725 - val_loss: 0.0815 - val_mae: 0.2067\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 21s/step - loss: 0.0223 - mae: 0.0737 - val_loss: 0.0792 - val_mae: 0.2030\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 21s/step - loss: 0.0212 - mae: 0.0714 - val_loss: 0.0776 - val_mae: 0.2003\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0220 - mae: 0.0739 - val_loss: 0.0756 - val_mae: 0.1971\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0213 - mae: 0.0722 - val_loss: 0.0741 - val_mae: 0.1945\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0210 - mae: 0.0710 - val_loss: 0.0720 - val_mae: 0.1910\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 21s/step - loss: 0.0203 - mae: 0.0693 - val_loss: 0.0698 - val_mae: 0.1871\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 21s/step - loss: 0.0220 - mae: 0.0733 - val_loss: 0.0679 - val_mae: 0.1839\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 21s/step - loss: 0.0206 - mae: 0.0696 - val_loss: 0.0660 - val_mae: 0.1806\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 21s/step - loss: 0.0211 - mae: 0.0713 - val_loss: 0.0643 - val_mae: 0.1775\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 21s/step - loss: 0.0218 - mae: 0.0725 - val_loss: 0.0620 - val_mae: 0.1732\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 21s/step - loss: 0.0213 - mae: 0.0714 - val_loss: 0.0599 - val_mae: 0.1696\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 21s/step - loss: 0.0210 - mae: 0.0710 - val_loss: 0.0589 - val_mae: 0.1672\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 21s/step - loss: 0.0211 - mae: 0.0715 - val_loss: 0.0567 - val_mae: 0.1632\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 20s/step - loss: 0.0199 - mae: 0.0682 - val_loss: 0.0539 - val_mae: 0.1582\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0198 - mae: 0.0677 - val_loss: 0.0520 - val_mae: 0.1543\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0200 - mae: 0.0678 - val_loss: 0.0502 - val_mae: 0.1506\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 21s/step - loss: 0.0203 - mae: 0.0686 - val_loss: 0.0488 - val_mae: 0.1478\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 21s/step - loss: 0.0205 - mae: 0.0696 - val_loss: 0.0467 - val_mae: 0.1435\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 21s/step - loss: 0.0215 - mae: 0.0714 - val_loss: 0.0449 - val_mae: 0.1398\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0210 - mae: 0.0705 - val_loss: 0.0436 - val_mae: 0.1369\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0197 - mae: 0.0675 - val_loss: 0.0418 - val_mae: 0.1328\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0205 - mae: 0.0701 - val_loss: 0.0401 - val_mae: 0.1289\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0208 - mae: 0.0697 - val_loss: 0.0384 - val_mae: 0.1250\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0198 - mae: 0.0673 - val_loss: 0.0366 - val_mae: 0.1208\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0196 - mae: 0.0671 - val_loss: 0.0357 - val_mae: 0.1187\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 22s/step - loss: 0.0202 - mae: 0.0683 - val_loss: 0.0343 - val_mae: 0.1149\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0206 - mae: 0.0693 - val_loss: 0.0327 - val_mae: 0.1108\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0196 - mae: 0.0667 - val_loss: 0.0312 - val_mae: 0.1071\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0205 - mae: 0.0689 - val_loss: 0.0303 - val_mae: 0.1043\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0198 - mae: 0.0674 - val_loss: 0.0298 - val_mae: 0.1030\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0204 - mae: 0.0688 - val_loss: 0.0278 - val_mae: 0.0974\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0203 - mae: 0.0683 - val_loss: 0.0273 - val_mae: 0.0960\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0202 - mae: 0.0688 - val_loss: 0.0266 - val_mae: 0.0936\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0193 - mae: 0.0659 - val_loss: 0.0249 - val_mae: 0.0885\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0197 - mae: 0.0671 - val_loss: 0.0249 - val_mae: 0.0883\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0192 - mae: 0.0658 - val_loss: 0.0256 - val_mae: 0.0898\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0193 - mae: 0.0660 - val_loss: 0.0242 - val_mae: 0.0839\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0190 - mae: 0.0649 - val_loss: 0.0232 - val_mae: 0.0818\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0181 - mae: 0.0629 - val_loss: 0.0241 - val_mae: 0.0837\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0194 - mae: 0.0666 - val_loss: 0.0228 - val_mae: 0.0789\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0191 - mae: 0.0660 - val_loss: 0.0214 - val_mae: 0.0757\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0191 - mae: 0.0653 - val_loss: 0.0205 - val_mae: 0.0724\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0194 - mae: 0.0659 - val_loss: 0.0224 - val_mae: 0.0768\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0193 - mae: 0.0655 - val_loss: 0.0213 - val_mae: 0.0733\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0191 - mae: 0.0656 - val_loss: 0.0204 - val_mae: 0.0699\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0190 - mae: 0.0653 - val_loss: 0.0249 - val_mae: 0.0797\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0190 - mae: 0.0647 - val_loss: 0.0207 - val_mae: 0.0701\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0192 - mae: 0.0652 - val_loss: 0.0303 - val_mae: 0.0902\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0185 - mae: 0.0641 - val_loss: 0.0219 - val_mae: 0.0719\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 22s/step - loss: 0.0188 - mae: 0.0655 - val_loss: 0.0222 - val_mae: 0.0734\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0186 - mae: 0.0644 - val_loss: 0.0190 - val_mae: 0.0657\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0183 - mae: 0.0633 - val_loss: 0.0217 - val_mae: 0.0711\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0178 - mae: 0.0625 - val_loss: 0.0196 - val_mae: 0.0668\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0180 - mae: 0.0628 - val_loss: 0.0186 - val_mae: 0.0637\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 22s/step - loss: 0.0177 - mae: 0.0618 - val_loss: 0.0212 - val_mae: 0.0694\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 22s/step - loss: 0.0171 - mae: 0.0607 - val_loss: 0.0232 - val_mae: 0.0731\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 27s/step - loss: 0.0168 - mae: 0.0601 - val_loss: 0.0197 - val_mae: 0.0660\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0171 - mae: 0.0606 - val_loss: 0.0204 - val_mae: 0.0677\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0164 - mae: 0.0590 - val_loss: 0.0198 - val_mae: 0.0662\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 22s/step - loss: 0.0157 - mae: 0.0572 - val_loss: 0.0198 - val_mae: 0.0664\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0161 - mae: 0.0582 - val_loss: 0.0197 - val_mae: 0.0662\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0164 - mae: 0.0595 - val_loss: 0.0252 - val_mae: 0.0775\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 22s/step - loss: 0.0156 - mae: 0.0575 - val_loss: 0.0208 - val_mae: 0.0685\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 22s/step - loss: 0.0151 - mae: 0.0563 - val_loss: 0.0201 - val_mae: 0.0667\n",
      "Saved both best and final model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Create model\n",
    "input_shape = (256, 256, 1)  # Adjustable\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=combined_loss,\n",
    "              metrics=['mae'])\n",
    "\n",
    "# Callback to save the best model (based on val_loss)\n",
    "checkpoint_cb = ModelCheckpoint(\"best_unet_model_rgb_V2.keras\", save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Stop training early if no improvement\n",
    "earlystop_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")\n",
    "\n",
    "# Save final model \n",
    "model.save(\"final_trained_unet_rgb_v2.keras\")\n",
    "print(\"Saved both best and final model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual save the model\n",
    "model.save(\"improved_unet_colorization_rgb_comics.keras\")\n",
    "print(\"Model saved as 'improved_unet_colorization_rgb_comics.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some results\n",
    "def plot_results(model, X, y, num_samples=3):\n",
    "    predictions = model.predict(X[:num_samples])\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    titles = ['Grayscale Input', 'Predicted Color', 'Ground Truth']\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(X[i].squeeze(), cmap='gray')\n",
    "        axes[i, 1].imshow(predictions[i])\n",
    "        axes[i, 2].imshow(y[i])\n",
    "        \n",
    "        for j in range(3):\n",
    "            axes[i, j].axis('off')\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(titles[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot test results\n",
    "plot_results(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variables\n",
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
