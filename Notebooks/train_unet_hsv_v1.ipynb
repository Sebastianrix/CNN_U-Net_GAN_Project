{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HSV U-Net Model -->\n",
    "<div class=\"alert\" style=\"background: linear-gradient(to right, hsl(0,100%,50%), hsl(120,100%,50%), hsl(240,100%,50%)); color:white;\">\n",
    "\n",
    "# **U-NET HSV Colorization Model**\n",
    "***\n",
    "This notebook implements a U-Net model for image colorization using the HSV color space. The model takes grayscale images (Value channel) as input and predicts the Hue and Saturation channels.\n",
    "\n",
    "### Key Features:\n",
    "- HSV color space for intuitive color prediction\n",
    "- Value channel as input (similar to grayscale)\n",
    "- Predicts Hue (color) and Saturation (intensity)\n",
    "- TensorBoard integration for monitoring\n",
    "- Custom loss function for circular Hue values\n",
    "\n",
    "### Model Architecture:\n",
    "- Input: Grayscale image (mapped to Value channel)\n",
    "- Output: Hue and Saturation channels\n",
    "- Encoder: 3 levels with increasing filters (64, 128, 256)\n",
    "- Bottleneck: 512 filters with dropout\n",
    "- Decoder: 3 levels with skip connections\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsv(rgb_images):\n",
    "    \"\"\"Convert RGB images to HSV format.\"\"\"\n",
    "    # Ensure the input is in the correct range [0, 1]\n",
    "    rgb_images = np.clip(rgb_images, 0, 1)\n",
    "    \n",
    "    # Convert to HSV using OpenCV (which expects BGR in range [0, 255])\n",
    "    hsv_images = np.zeros_like(rgb_images)\n",
    "    for i in range(len(rgb_images)):\n",
    "        # Convert to BGR and scale to [0, 255]\n",
    "        bgr = (rgb_images[i] * 255).astype(np.uint8)\n",
    "        bgr = cv2.cvtColor(bgr, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert to HSV\n",
    "        hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Normalize back to [0, 1]\n",
    "        hsv_images[i] = hsv.astype(np.float32) / np.array([179, 255, 255])\n",
    "    \n",
    "    return hsv_images\n",
    "\n",
    "def hsv_to_rgb(hsv_images):\n",
    "    \"\"\"Convert HSV images back to RGB format.\"\"\"\n",
    "    # Scale HSV values to OpenCV ranges\n",
    "    hsv_images_cv = hsv_images * np.array([179, 255, 255])\n",
    "    hsv_images_cv = hsv_images_cv.astype(np.uint8)\n",
    "    \n",
    "    rgb_images = np.zeros((*hsv_images.shape[:-1], 3))\n",
    "    for i in range(len(hsv_images)):\n",
    "        # Convert to BGR then RGB\n",
    "        bgr = cv2.cvtColor(hsv_images_cv[i], cv2.COLOR_HSV2BGR)\n",
    "        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        rgb_images[i] = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "    return rgb_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet_hsv(input_shape=(256, 256, 1)):\n",
    "    \"\"\"Build U-Net model for HSV color space prediction.\"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.BatchNormalization()(conv4)\n",
    "    conv4 = layers.Dropout(0.3)(conv4)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv4)\n",
    "    concat5 = layers.Concatenate()([conv3, up5])\n",
    "    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(concat5)\n",
    "    conv5 = layers.BatchNormalization()(conv5)\n",
    "    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    concat6 = layers.Concatenate()([conv2, up6])\n",
    "    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(concat6)\n",
    "    conv6 = layers.BatchNormalization()(conv6)\n",
    "    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    concat7 = layers.Concatenate()([conv1, up7])\n",
    "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(concat7)\n",
    "    conv7 = layers.BatchNormalization()(conv7)\n",
    "    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    # Output layer - 2 channels for H and S\n",
    "    outputs = layers.Conv2D(2, 1, activation='sigmoid')(conv7)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_loss(y_true, y_pred):\n",
    "    \"\"\"Custom loss function for HSV color space.\n",
    "    Handles the circular nature of Hue channel and regular MSE for Saturation.\"\"\"\n",
    "    \n",
    "    # Split into Hue and Saturation channels\n",
    "    h_true, s_true = tf.split(y_true, 2, axis=-1)\n",
    "    h_pred, s_pred = tf.split(y_pred, 2, axis=-1)\n",
    "    \n",
    "    # Circular loss for Hue\n",
    "    h_diff = tf.abs(h_true - h_pred)\n",
    "    h_loss = tf.minimum(h_diff, 1 - h_diff)  # Account for circular nature of hue\n",
    "    h_loss = tf.reduce_mean(tf.square(h_loss))\n",
    "    \n",
    "    # Regular MSE for Saturation\n",
    "    s_loss = tf.reduce_mean(tf.square(s_true - s_pred))\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    return 0.7 * h_loss + 0.3 * s_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "print(\"Loading training data...\")\n",
    "X_train = np.load(\"../Data/prepared_data/comic_input_grayscale_train.npy\")\n",
    "y_train = np.load(\"../Data/prepared_data/comic_output_color_train.npy\")\n",
    "X_test = np.load(\"../Data/prepared_data/comic_input_grayscale_test.npy\")\n",
    "y_test = np.load(\"../Data/prepared_data/comic_output_color_test.npy\")\n",
    "\n",
    "# Convert RGB targets to HSV\n",
    "print(\"Converting to HSV color space...\")\n",
    "y_train_hsv = rgb_to_hsv(y_train)\n",
    "y_test_hsv = rgb_to_hsv(y_test)\n",
    "\n",
    "# Extract H and S channels for training targets\n",
    "y_train_hs = y_train_hsv[:, :, :, :2]  # First two channels are H and S\n",
    "y_test_hs = y_test_hsv[:, :, :, :2]\n",
    "\n",
    "# Normalize input images to [-1, 1] range\n",
    "X_train = (X_train - 0.5) * 2\n",
    "X_test = (X_test - 0.5) * 2\n",
    "\n",
    "print(\"\\nData shapes:\")\n",
    "print(f\"X_train: {X_train.shape} (normalized to [-1, 1])\")\n",
    "print(f\"y_train_hs: {y_train_hs.shape} (H and S channels)\")\n",
    "print(f\"X_test: {X_test.shape} (normalized to [-1, 1])\")\n",
    "print(f\"y_test_hs: {y_test_hs.shape} (H and S channels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories for logs and checkpoints\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join('logs', f'hsv_unet_{timestamp}')\n",
    "checkpoint_dir = os.path.join('../Models', f'hsv_unet_{timestamp}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Create callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}.h5'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    ),\n",
    "    TensorBoard(log_dir=log_dir),\n",
    "    EarlyStopping(patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Build and compile model\n",
    "model = build_unet_hsv(input_shape=(256, 256, 1))\n",
    "model.compile(optimizer='adam', loss=hsv_loss, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_hs,\n",
    "    validation_data=(X_test, y_test_hs),\n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, X, y_true_rgb, num_samples=5):\n",
    "    \"\"\"Plot original, grayscale and predicted images.\"\"\"\n",
    "    # Get predictions\n",
    "    y_pred_hs = model.predict(X[:num_samples])\n",
    "    \n",
    "    # Create full HSV images (combine predicted H,S with original V)\n",
    "    v_channel = (X[:num_samples] / 2 + 0.5)  # Denormalize V channel\n",
    "    y_pred_hsv = np.concatenate([y_pred_hs, v_channel], axis=-1)\n",
    "    \n",
    "    # Convert to RGB for visualization\n",
    "    y_pred_rgb = hsv_to_rgb(y_pred_hsv)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 3*num_samples))\n",
    "    for i in range(num_samples):\n",
    "        # Original\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(y_true_rgb[i])\n",
    "        plt.title('Original' if i == 0 else '')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Grayscale\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(X[i].squeeze(), cmap='gray')\n",
    "        plt.title('Grayscale' if i == 0 else '')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Predicted\n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(y_pred_rgb[i])\n",
    "        plt.title('Predicted' if i == 0 else '')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some test results\n",
    "plot_results(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 